{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abaee6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4439bcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1796d2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0ce38a6830>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d52ca2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Baseline, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=\"same\")\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=\"same\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=32)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=32)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=\"same\")\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=\"same\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=64)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=64)\n",
    "        self.dropout2 = nn.Dropout(p=0.3)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=\"same\")\n",
    "        self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=\"same\")\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.bn5 = nn.BatchNorm2d(num_features=128)\n",
    "        self.bn6 = nn.BatchNorm2d(num_features=128)\n",
    "        self.dropout3 = nn.Dropout(p=0.4)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=2048, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=128)\n",
    "        self.fc3 = nn.Linear(in_features=128, out_features=128)\n",
    "        self.fc4 = nn.Linear(in_features=128, out_features=128)\n",
    "        self.bn7 = nn.BatchNorm1d(num_features=128)\n",
    "        self.dropout4 = nn.Dropout(p=0.5)\n",
    "        self.fc5 = nn.Linear(in_features=128, out_features=100)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn1(x)\n",
    "        outputs.append(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        outputs.append(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn3(x)\n",
    "        outputs.append(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        outputs.append(x)\n",
    "        \n",
    "        x = self.conv5(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn5(x)\n",
    "        outputs.append(x)\n",
    "        x = self.conv6(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn6(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.dropout3(x)\n",
    "        outputs.append(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn7(x)\n",
    "        x = self.dropout4(x)\n",
    "        scores = self.fc5(x)\n",
    "        \n",
    "        return scores, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1ca5a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e0b262e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = CIFAR100(root='./data', download=True, transform=ToTensor())\n",
    "test_dataset = CIFAR100(root='./data', train=False, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e6e2a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "val_size = 5000\n",
    "train_size = len(dataset) - val_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size*2, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size*2, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78da91d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Baseline().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fff55503",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=.001, momentum=0.9)\n",
    "epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0048c44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1]: t_loss: 4.52053 t_acc: 3.02889 v_loss: 4.294 v_acc: 5.2\n",
      "Epoch[2]: t_loss: 4.14867 t_acc: 7.04667 v_loss: 4.00301 v_acc: 8.9\n",
      "Epoch[3]: t_loss: 3.91518 t_acc: 10.28889 v_loss: 3.80077 v_acc: 13.22\n",
      "Epoch[4]: t_loss: 3.74573 t_acc: 12.65111 v_loss: 3.5678 v_acc: 17.72\n",
      "Epoch[5]: t_loss: 3.59973 t_acc: 15.15333 v_loss: 3.4978 v_acc: 18.12\n",
      "Epoch[6]: t_loss: 3.46277 t_acc: 17.03778 v_loss: 3.3246 v_acc: 21.72\n",
      "Epoch[7]: t_loss: 3.33449 t_acc: 19.25111 v_loss: 3.16923 v_acc: 23.76\n",
      "Epoch[8]: t_loss: 3.21593 t_acc: 21.65333 v_loss: 3.03888 v_acc: 26.54\n",
      "Epoch[9]: t_loss: 3.09475 t_acc: 23.72222 v_loss: 2.88718 v_acc: 29.14\n",
      "Epoch[10]: t_loss: 2.99724 t_acc: 25.20889 v_loss: 2.80738 v_acc: 30.44\n",
      "Epoch[11]: t_loss: 2.90938 t_acc: 26.9 v_loss: 2.69789 v_acc: 32.4\n",
      "Epoch[12]: t_loss: 2.82508 t_acc: 28.49333 v_loss: 2.64798 v_acc: 33.3\n",
      "Epoch[13]: t_loss: 2.75545 t_acc: 30.11333 v_loss: 2.5727 v_acc: 34.1\n",
      "Epoch[14]: t_loss: 2.68681 t_acc: 31.09778 v_loss: 2.57384 v_acc: 34.1\n",
      "Epoch[15]: t_loss: 2.6163 t_acc: 32.59556 v_loss: 2.54092 v_acc: 34.74\n",
      "Epoch[16]: t_loss: 2.56503 t_acc: 33.79556 v_loss: 2.39729 v_acc: 37.5\n",
      "Epoch[17]: t_loss: 2.51256 t_acc: 34.87111 v_loss: 2.38311 v_acc: 36.94\n",
      "Epoch[18]: t_loss: 2.45943 t_acc: 35.91556 v_loss: 2.30505 v_acc: 38.82\n",
      "Epoch[19]: t_loss: 2.42096 t_acc: 36.55333 v_loss: 2.30754 v_acc: 38.44\n",
      "Epoch[20]: t_loss: 2.36691 t_acc: 37.9 v_loss: 2.24494 v_acc: 40.68\n",
      "Epoch[21]: t_loss: 2.33711 t_acc: 38.62889 v_loss: 2.1991 v_acc: 41.96\n",
      "Epoch[22]: t_loss: 2.29544 t_acc: 39.14667 v_loss: 2.18263 v_acc: 42.1\n",
      "Epoch[23]: t_loss: 2.25895 t_acc: 40.11333 v_loss: 2.17488 v_acc: 42.16\n",
      "Epoch[24]: t_loss: 2.21366 t_acc: 41.25111 v_loss: 2.11153 v_acc: 43.82\n",
      "Epoch[25]: t_loss: 2.178 t_acc: 41.99778 v_loss: 2.07686 v_acc: 44.56\n",
      "Epoch[26]: t_loss: 2.14894 t_acc: 42.59778 v_loss: 2.05687 v_acc: 44.62\n",
      "Epoch[27]: t_loss: 2.11754 t_acc: 43.15778 v_loss: 2.03393 v_acc: 45.26\n",
      "Epoch[28]: t_loss: 2.0846 t_acc: 44.0 v_loss: 2.04028 v_acc: 44.8\n",
      "Epoch[29]: t_loss: 2.05223 t_acc: 44.85333 v_loss: 1.97547 v_acc: 46.88\n",
      "Epoch[30]: t_loss: 2.02126 t_acc: 45.31111 v_loss: 1.96799 v_acc: 47.22\n",
      "Epoch[31]: t_loss: 1.99526 t_acc: 46.09333 v_loss: 1.97776 v_acc: 46.6\n",
      "Epoch[32]: t_loss: 1.97139 t_acc: 46.55111 v_loss: 1.9653 v_acc: 46.6\n",
      "Epoch[33]: t_loss: 1.93498 t_acc: 47.42222 v_loss: 1.93287 v_acc: 48.06\n",
      "Epoch[34]: t_loss: 1.92351 t_acc: 47.64667 v_loss: 1.91325 v_acc: 48.82\n",
      "Epoch[35]: t_loss: 1.88697 t_acc: 48.52444 v_loss: 1.93165 v_acc: 48.38\n",
      "Epoch[36]: t_loss: 1.87744 t_acc: 48.96889 v_loss: 1.90157 v_acc: 48.5\n",
      "Epoch[37]: t_loss: 1.84436 t_acc: 49.61556 v_loss: 1.90378 v_acc: 48.94\n",
      "Epoch[38]: t_loss: 1.82108 t_acc: 50.22889 v_loss: 1.8662 v_acc: 49.88\n",
      "Epoch[39]: t_loss: 1.80836 t_acc: 50.80222 v_loss: 1.86247 v_acc: 49.32\n",
      "Epoch[40]: t_loss: 1.78005 t_acc: 51.16 v_loss: 1.87053 v_acc: 48.98\n",
      "Epoch[41]: t_loss: 1.76205 t_acc: 51.62667 v_loss: 1.89278 v_acc: 49.46\n",
      "Epoch[42]: t_loss: 1.74037 t_acc: 52.07111 v_loss: 1.85076 v_acc: 50.56\n",
      "Epoch[43]: t_loss: 1.7211 t_acc: 52.57778 v_loss: 1.82709 v_acc: 50.92\n",
      "Epoch[44]: t_loss: 1.70235 t_acc: 52.94444 v_loss: 1.84176 v_acc: 50.16\n",
      "Epoch[45]: t_loss: 1.68035 t_acc: 53.87111 v_loss: 1.81926 v_acc: 50.62\n",
      "Epoch[46]: t_loss: 1.66001 t_acc: 53.89111 v_loss: 1.87259 v_acc: 49.78\n",
      "Epoch[47]: t_loss: 1.64391 t_acc: 54.53778 v_loss: 1.79849 v_acc: 50.84\n",
      "Epoch[48]: t_loss: 1.6235 t_acc: 54.87111 v_loss: 1.86141 v_acc: 50.62\n",
      "Epoch[49]: t_loss: 1.61069 t_acc: 55.39333 v_loss: 1.8116 v_acc: 50.88\n",
      "Epoch[50]: t_loss: 1.59015 t_acc: 55.71778 v_loss: 1.77608 v_acc: 51.92\n",
      "Epoch[51]: t_loss: 1.58142 t_acc: 55.86667 v_loss: 1.7628 v_acc: 53.0\n",
      "Epoch[52]: t_loss: 1.54724 t_acc: 56.83111 v_loss: 1.78756 v_acc: 51.98\n",
      "Epoch[53]: t_loss: 1.53825 t_acc: 57.14 v_loss: 1.7703 v_acc: 52.08\n",
      "Epoch[54]: t_loss: 1.52902 t_acc: 57.04667 v_loss: 1.78507 v_acc: 52.58\n",
      "Epoch[55]: t_loss: 1.51472 t_acc: 57.81556 v_loss: 1.75369 v_acc: 52.7\n",
      "Epoch[56]: t_loss: 1.49472 t_acc: 57.97111 v_loss: 1.77997 v_acc: 53.0\n",
      "Epoch[57]: t_loss: 1.48166 t_acc: 58.20667 v_loss: 1.80948 v_acc: 51.84\n",
      "Epoch[58]: t_loss: 1.46645 t_acc: 58.74667 v_loss: 1.80497 v_acc: 51.58\n",
      "Epoch[59]: t_loss: 1.44321 t_acc: 59.37333 v_loss: 1.7876 v_acc: 52.64\n",
      "Epoch[60]: t_loss: 1.43227 t_acc: 59.54667 v_loss: 1.79826 v_acc: 52.46\n",
      "Epoch[61]: t_loss: 1.41327 t_acc: 60.14444 v_loss: 1.81291 v_acc: 52.46\n",
      "Epoch[62]: t_loss: 1.40726 t_acc: 60.38222 v_loss: 1.76043 v_acc: 53.26\n",
      "Epoch[63]: t_loss: 1.39536 t_acc: 60.43778 v_loss: 1.73512 v_acc: 54.22\n",
      "Epoch[64]: t_loss: 1.37965 t_acc: 61.00444 v_loss: 1.7565 v_acc: 52.88\n",
      "Epoch[65]: t_loss: 1.3692 t_acc: 61.16222 v_loss: 1.76496 v_acc: 53.54\n",
      "Epoch[66]: t_loss: 1.35049 t_acc: 61.79778 v_loss: 1.73039 v_acc: 53.82\n",
      "Epoch[67]: t_loss: 1.34216 t_acc: 61.97333 v_loss: 1.76585 v_acc: 53.76\n",
      "Epoch[68]: t_loss: 1.33031 t_acc: 62.11778 v_loss: 1.75343 v_acc: 54.04\n",
      "Epoch[69]: t_loss: 1.32745 t_acc: 62.4 v_loss: 1.77142 v_acc: 53.82\n",
      "Epoch[70]: t_loss: 1.30241 t_acc: 63.16222 v_loss: 1.74956 v_acc: 53.9\n",
      "Epoch[71]: t_loss: 1.28738 t_acc: 63.32667 v_loss: 1.76942 v_acc: 53.0\n",
      "Epoch[72]: t_loss: 1.28343 t_acc: 63.42444 v_loss: 1.76404 v_acc: 53.22\n",
      "Epoch[73]: t_loss: 1.26681 t_acc: 63.86222 v_loss: 1.75503 v_acc: 54.12\n",
      "Epoch[74]: t_loss: 1.26296 t_acc: 63.88444 v_loss: 1.75378 v_acc: 54.16\n",
      "Epoch[75]: t_loss: 1.25053 t_acc: 64.39778 v_loss: 1.74608 v_acc: 54.04\n",
      "Epoch[76]: t_loss: 1.23817 t_acc: 64.77333 v_loss: 1.7618 v_acc: 54.08\n",
      "Finished Training\n",
      "Best model saved at epoch:  66\n"
     ]
    }
   ],
   "source": [
    "best_val_epoch, best_val_loss = 0, 1e6\n",
    "break_flag = 0\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    model.train()\n",
    "    t_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        t_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    t_loss = t_loss / (i+1)\n",
    "    t_loss = round(t_loss, 5)\n",
    "    t_acc = round(100*(correct / total), 5)\n",
    "    model.eval()\n",
    "    v_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(val_loader):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs, _ = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        v_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    v_loss = v_loss/(i+1)\n",
    "    v_loss = round(v_loss, 5)\n",
    "    v_acc = round(100*(correct / total), 5)\n",
    "    if v_loss <= best_val_loss:\n",
    "        torch.save(model.state_dict(), \"cifar100_baseline_m.h5\")\n",
    "        best_val_epoch = epoch + 1\n",
    "        best_val_loss = v_loss\n",
    "        break_flag = 0\n",
    "    else:\n",
    "        break_flag += 1\n",
    "    print(f'Epoch[{epoch+1}]: t_loss: {t_loss} t_acc: {t_acc} v_loss: {v_loss} v_acc: {v_acc}')\n",
    "    if break_flag >9 :\n",
    "        break\n",
    "print('Finished Training')\n",
    "print('Best model saved at epoch: ', best_val_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4d063a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 55.01\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"cifar100_baseline_m.h5\", map_location='cpu'))\n",
    "correct = 0\n",
    "total = 0\n",
    "pred, actual = [], []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs, _ = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        pred = pred + list(predicted.detach().cpu().numpy())\n",
    "        actual = actual + list(labels.detach().cpu().numpy())\n",
    "print(f'Test accuracy: {100 * correct /total}')       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
