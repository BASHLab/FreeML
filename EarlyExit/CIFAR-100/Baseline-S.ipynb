{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abaee6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4439bcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1796d2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1ef3cc1850>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d52ca2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Baseline, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=\"valid\")\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=\"valid\")\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, padding=\"valid\")\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=43264, out_features=256)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=64)\n",
    "        self.fc3 = nn.Linear(in_features=64, out_features=100)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        exit_outputs = []\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        exit_outputs.append(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        exit_outputs.append(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        exit_outputs.append(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x, exit_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1ca5a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e0b262e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 169001437/169001437 [00:15<00:00, 11200242.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-100-python.tar.gz to ./data\n"
     ]
    }
   ],
   "source": [
    "dataset = CIFAR100(root='./data', download=True, transform=ToTensor())\n",
    "test_dataset = CIFAR100(root='./data', train=False, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e6e2a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "val_size = 5000\n",
    "train_size = len(dataset) - val_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size*2, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size*2, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78da91d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Baseline().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fff55503",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=3e-3, momentum=0.9)\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0048c44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1]: t_loss: 4.5125 t_acc: 2.58444 v_loss: 4.18967 v_acc: 6.48\n",
      "Epoch[2]: t_loss: 3.95849 t_acc: 10.05778 v_loss: 3.81763 v_acc: 12.34\n",
      "Epoch[3]: t_loss: 3.73266 t_acc: 13.84222 v_loss: 3.67824 v_acc: 15.48\n",
      "Epoch[4]: t_loss: 3.56998 t_acc: 17.08889 v_loss: 3.57207 v_acc: 16.06\n",
      "Epoch[5]: t_loss: 3.42936 t_acc: 19.45333 v_loss: 3.40389 v_acc: 20.28\n",
      "Epoch[6]: t_loss: 3.3127 t_acc: 21.43556 v_loss: 3.34443 v_acc: 22.04\n",
      "Epoch[7]: t_loss: 3.22754 t_acc: 23.14889 v_loss: 3.29716 v_acc: 22.42\n",
      "Epoch[8]: t_loss: 3.12793 t_acc: 24.99556 v_loss: 3.21594 v_acc: 23.26\n",
      "Epoch[9]: t_loss: 3.01663 t_acc: 27.25556 v_loss: 3.14099 v_acc: 25.3\n",
      "Epoch[10]: t_loss: 2.9035 t_acc: 29.31333 v_loss: 3.06493 v_acc: 25.84\n",
      "Epoch[11]: t_loss: 2.7831 t_acc: 31.51111 v_loss: 3.00909 v_acc: 27.64\n",
      "Epoch[12]: t_loss: 2.65864 t_acc: 33.96889 v_loss: 2.93523 v_acc: 28.68\n",
      "Epoch[13]: t_loss: 2.52694 t_acc: 36.77111 v_loss: 2.91266 v_acc: 29.62\n",
      "Epoch[14]: t_loss: 2.40229 t_acc: 39.51111 v_loss: 2.88949 v_acc: 30.74\n",
      "Epoch[15]: t_loss: 2.24849 t_acc: 42.38222 v_loss: 2.94084 v_acc: 30.4\n",
      "Epoch[16]: t_loss: 2.10083 t_acc: 45.81111 v_loss: 2.93287 v_acc: 31.94\n",
      "Epoch[17]: t_loss: 1.93949 t_acc: 49.31111 v_loss: 3.00665 v_acc: 30.84\n",
      "Epoch[18]: t_loss: 1.75664 t_acc: 53.18 v_loss: 3.05521 v_acc: 30.94\n",
      "Epoch[19]: t_loss: 1.55956 t_acc: 58.07556 v_loss: 3.24153 v_acc: 29.78\n",
      "Epoch[20]: t_loss: 1.33007 t_acc: 63.39111 v_loss: 3.42706 v_acc: 28.9\n",
      "Epoch[21]: t_loss: 1.09379 t_acc: 69.55556 v_loss: 3.77178 v_acc: 28.74\n",
      "Epoch[22]: t_loss: 0.85641 t_acc: 75.48222 v_loss: 4.09853 v_acc: 29.22\n",
      "Epoch[23]: t_loss: 0.63598 t_acc: 81.60889 v_loss: 4.52803 v_acc: 27.18\n",
      "Epoch[24]: t_loss: 0.43936 t_acc: 86.94889 v_loss: 5.34851 v_acc: 27.08\n",
      "Finished Training\n",
      "Best model saved at epoch:  14\n"
     ]
    }
   ],
   "source": [
    "best_val_epoch, best_val_loss = 0, 1e6\n",
    "break_flag = 0\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    model.train()\n",
    "    t_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        t_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    t_loss = t_loss / (i+1)\n",
    "    t_loss = round(t_loss, 5)\n",
    "    t_acc = round(100*(correct / total), 5)\n",
    "    model.eval()\n",
    "    v_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(val_loader):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs, _ = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        v_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    v_loss = v_loss/(i+1)\n",
    "    v_loss = round(v_loss, 5)\n",
    "    v_acc = round(100*(correct / total), 5)\n",
    "    if v_loss <= best_val_loss:\n",
    "        torch.save(model.state_dict(), \"cifar100_baseline_s.h5\")\n",
    "        best_val_epoch = epoch + 1\n",
    "        best_val_loss = v_loss\n",
    "        break_flag = 0\n",
    "    else:\n",
    "        break_flag += 1\n",
    "    print(f'Epoch[{epoch+1}]: t_loss: {t_loss} t_acc: {t_acc} v_loss: {v_loss} v_acc: {v_acc}')\n",
    "    if break_flag >9 :\n",
    "        break\n",
    "print('Finished Training')\n",
    "print('Best model saved at epoch: ', best_val_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4d063a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 31.26\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"cifar100_baseline_s.h5\", map_location='cpu'))\n",
    "correct = 0\n",
    "total = 0\n",
    "pred, actual = [], []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs, _ = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        pred = pred + list(predicted.detach().cpu().numpy())\n",
    "        actual = actual + list(labels.detach().cpu().numpy())\n",
    "print(f'Test accuracy: {100 * correct /total}')       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
